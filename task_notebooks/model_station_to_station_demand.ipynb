{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook creates a Bayesian geospatial gravity model to estimate the bike ride demand between\n",
    "stations based on previous data. It also goes over visualizing the results with a flow map.\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "# File name for the final model results\n",
    "MODEL_RESULTS_FILE = \"../models/time_series.nc\"\n",
    "\n",
    "# File path to the saved station hierarchy model\n",
    "HIERARCHICAL_MODEL_FILE_PATH = \"../models/station_pop_model_results.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56405d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       trip_id  duration          start_time             end_time  \\\n",
      "0  144361832.0      12.0 2017-07-01 00:04:00  2017-07-01 00:16:00   \n",
      "1  144361829.0      31.0 2017-07-01 00:06:00  2017-07-01 00:37:00   \n",
      "2  144361830.0      15.0 2017-07-01 00:06:00  2017-07-01 00:21:00   \n",
      "3  144361831.0      15.0 2017-07-01 00:06:00  2017-07-01 00:21:00   \n",
      "4  144361828.0      30.0 2017-07-01 00:07:00  2017-07-01 00:37:00   \n",
      "\n",
      "   start_station  start_lat  start_lon  end_station    end_lat    end_lon  \\\n",
      "0         3160.0  39.956619 -75.198624       3163.0  39.949741 -75.180969   \n",
      "1         3046.0  39.950119 -75.144722       3101.0  39.942951 -75.159554   \n",
      "2         3006.0  39.952202  -75.20311       3101.0  39.942951 -75.159554   \n",
      "3         3006.0  39.952202  -75.20311       3101.0  39.942951 -75.159554   \n",
      "4         3046.0  39.950119 -75.144722       3101.0  39.942951 -75.159554   \n",
      "\n",
      "  bike_id  plan_duration trip_route_category passholder_type bike_type  \n",
      "0   11883           30.0             One Way        Indego30       NaN  \n",
      "1    5394            0.0             One Way         Walk-up       NaN  \n",
      "2    3331           30.0             One Way        Indego30       NaN  \n",
      "3    3515           30.0             One Way        Indego30       NaN  \n",
      "4   11913            0.0             One Way         Walk-up       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load in the data\n",
    "df_bike = pd.read_pickle(\"../data/indego_bike_data.pkl\")\n",
    "\n",
    "# Subset to the last two years of data\n",
    "df_bike[\"start_time\"] = pd.to_datetime(\n",
    "    df_bike[\"start_time\"], format=\"mixed\"\n",
    ")\n",
    "cutoff_date = pd.to_datetime(\"2025-08-16\") - pd.DateOffset(years=2)\n",
    "df_bike_active = df_bike[df_bike[\"start_time\"] >= cutoff_date].copy()\n",
    "\n",
    "print(df_bike.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5bf38c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active stations: 272\n",
      "Active station IDs: [3000, 3005, 3006, 3007, 3008, 3009, 3010, 3012, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3024, 3025, 3026, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3037, 3038, 3039, 3040, 3041, 3047, 3049, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3072, 3073, 3074, 3075, 3077, 3078, 3086, 3088, 3093, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3104, 3106, 3107, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3123, 3124, 3125, 3150, 3152, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3168, 3169, 3181, 3182, 3183, 3184, 3185, 3187, 3188, 3196, 3197, 3200, 3201, 3203, 3204, 3205, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3226, 3235, 3236, 3237, 3238, 3240, 3241, 3243, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3258, 3259, 3261, 3263, 3264, 3265, 3266, 3267, 3271, 3272, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3284, 3285, 3286, 3287, 3291, 3294, 3295, 3296, 3298, 3299, 3300, 3292, 3297, 3301, 3303, 3304, 3305, 3306, 3307, 3310, 3313, 3314, 3315, 3316, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3326, 3327, 3328, 3329, 3331, 3332, 3334, 3335, 3336, 3337, 3338, 3340, 3268, 3325, 3333, 3341, 3342, 3344, 3345, 3346, 3347, 3349, 3350, 3351, 3353, 3352, 3354, 3356, 3357, 3359, 3360, 3361, 3365, 3368, 3362, 3363, 3369, 3370, 3371, 3372, 3373, 3375, 3376, 3378, 3381, 3382, 3383, 3374, 3387, 3388, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3385, 3389, 3399, 3400, 3405, 3407, 3408, 3409, 3410, 3411, 3403, 3412, 3414, 3417, 3418, 3421, 3422, 3425, 3430]\n",
      "       trip_id  duration          start_time             end_time  \\\n",
      "0  144361832.0      12.0 2017-07-01 00:04:00  2017-07-01 00:16:00   \n",
      "2  144361830.0      15.0 2017-07-01 00:06:00  2017-07-01 00:21:00   \n",
      "3  144361831.0      15.0 2017-07-01 00:06:00  2017-07-01 00:21:00   \n",
      "5  144361827.0      14.0 2017-07-01 00:08:00  2017-07-01 00:22:00   \n",
      "8  144384127.0      56.0 2017-07-01 00:16:00  2017-07-01 01:12:00   \n",
      "\n",
      "   start_station  start_lat  start_lon  end_station    end_lat    end_lon  \\\n",
      "0         3160.0  39.956619 -75.198624       3163.0  39.949741 -75.180969   \n",
      "2         3006.0  39.952202  -75.20311       3101.0  39.942951 -75.159554   \n",
      "3         3006.0  39.952202  -75.20311       3101.0  39.942951 -75.159554   \n",
      "5         3010.0  39.947109 -75.166183       3099.0   39.93401  -75.15094   \n",
      "8         3026.0   39.94138 -75.145638       3018.0  39.952728  -75.15979   \n",
      "\n",
      "  bike_id  plan_duration trip_route_category passholder_type bike_type  \n",
      "0   11883           30.0             One Way        Indego30       NaN  \n",
      "2    3331           30.0             One Way        Indego30       NaN  \n",
      "3    3515           30.0             One Way        Indego30       NaN  \n",
      "5    2555           30.0             One Way        Indego30       NaN  \n",
      "8   11900           30.0             One Way        Indego30       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load station data, including whether or not each station is active\n",
    "df_stations = pd.read_csv(\"../data/indego-stations-2025-07-01.csv\")\n",
    "df_stations[\"Station_ID\"] = df_stations[\"Station_ID\"].astype(\"Int64\")\n",
    "\n",
    "# Keep only station IDs where status is \"Active\"\n",
    "active_ids = df_stations.loc[df_stations[\"Status\"] == \"Active\", \"Station_ID\"]\n",
    "print(f\"Number of active stations: {len(active_ids)}\")\n",
    "print(f\"Active station IDs: {active_ids.tolist()}\")\n",
    "\n",
    "# Keep rides where BOTH start and end stations are active\n",
    "df_bike_active = df_bike[\n",
    "    df_bike[\"start_station\"].isin(active_ids) & df_bike[\"end_station\"].isin(active_ids)\n",
    "]\n",
    "\n",
    "# Setting some basic variables for downstream calculation\n",
    "n_stations = len(active_ids)\n",
    "station_lookup = {id: i for i, id in enumerate(active_ids)}\n",
    "station_ids_in_subset = sorted(pd.concat([df_bike_active['start_station'], df_bike_active['end_station']]).unique())\n",
    "station_lookup = {id: i for i, id in enumerate(station_ids_in_subset)}\n",
    "id_to_idx_map = {v: k for k, v in station_lookup.items()}\n",
    "\n",
    "print(df_bike_active.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de54ff",
   "metadata": {},
   "source": [
    "The final model for this project is a Bayesian geospatial gravity model. In simple terms, this model\n",
    "can treat each bike station as a planet in outer space, where their mass (popularity) attracts trips\n",
    "and the distance between each other creates friction that reduces the number of trips.\n",
    "\n",
    "The model can predict the number of trips between any two stations (but it cannot predict the \n",
    "number of trips between the same station) by considering the origin popularity, the destination\n",
    "popularity, and the distance. Combining each factor into a formula can get the expected number of \n",
    "trips for each origin-destination pair. This can help quantify the \"friction of distance\" and \n",
    "how much that reduces the likelihood of a trip.\n",
    "\n",
    "Note that this is diferent from the hierarchical model. That predicted the origin popularity for each \n",
    "day of the week, while this model can quantify the popularity between stations.\n",
    "\n",
    "This is also different from the static transition metric, which just showed historical trends, while\n",
    "this model aims to predict the demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c5d74",
   "metadata": {},
   "source": [
    "To do this, I first need to load in the hiararchical model to get the popularity scores for each\n",
    "station ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c052d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_station = az.from_netcdf(HIERARCHICAL_MODEL_FILE_PATH)\n",
    "posterior_samples = az.extract(idata_station)\n",
    "station_pop_est = posterior_samples['station_log_popularity'].mean(dim='sample').values\n",
    "\n",
    "# Create the station popularity score\n",
    "station_popularity = pd.Series(np.exp(station_pop_est), index=station_lookup.values())\n",
    "\n",
    "# Map each station ID to the station popularity\n",
    "station_id_to_pop_map = {st_id: station_popularity[idx] for idx, st_id in id_to_idx_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aecaf9c",
   "metadata": {},
   "source": [
    "Next, I need to create the Origin-Destination Matrix. This is a fundamental tool for general\n",
    "transportation analysis to help visualize the popularity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53455c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_station    3000.0  3005.0  3006.0  3007.0  3008.0  3009.0  3010.0  3012.0  \\\n",
      "start_station                                                                   \n",
      "3000.0            269       3       4       7       4       0       5       5   \n",
      "3005.0            363    2289      64     506      32     148     890     176   \n",
      "3006.0            651      48    3880     171       3    1021     431     524   \n",
      "3007.0           1166     636     167    5955     201     271    4217     995   \n",
      "3008.0            304      17       9     166    1355      44      86       9   \n",
      "...               ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "3418.0              6       0       0       0       1       0       0       0   \n",
      "3421.0              3       0       0      10       0       0       0       0   \n",
      "3422.0              6       0       1       0       0       7       3       0   \n",
      "3425.0              6       0       0       0       3       0       0       0   \n",
      "3430.0              2       0       0       2       0       0       0       0   \n",
      "\n",
      "end_station    3014.0  3015.0  ...  3410.0  3411.0  3412.0  3414.0  3417.0  \\\n",
      "start_station                  ...                                           \n",
      "3000.0              1       1  ...       0       0       0       0       0   \n",
      "3005.0             17     573  ...       0       0       0       0       0   \n",
      "3006.0            134      46  ...      16       1       0       1       0   \n",
      "3007.0             99     947  ...       0       0       0       0       0   \n",
      "3008.0              4      19  ...       0       0       0       0       1   \n",
      "...               ...     ...  ...     ...     ...     ...     ...     ...   \n",
      "3418.0              0       0  ...       0       0       0       0       0   \n",
      "3421.0              0       0  ...       0       0       0       0       0   \n",
      "3422.0              0       0  ...       0       0       0       0       0   \n",
      "3425.0              0       0  ...       0       0       0       0       3   \n",
      "3430.0              0       0  ...       0       0       0       0       0   \n",
      "\n",
      "end_station    3418.0  3421.0  3422.0  3425.0  3430.0  \n",
      "start_station                                          \n",
      "3000.0              0       0       0       0       0  \n",
      "3005.0              0       0       0       3       0  \n",
      "3006.0              0       0       1       0       0  \n",
      "3007.0              0       9       0       1       2  \n",
      "3008.0              1       0       0       1       0  \n",
      "...               ...     ...     ...     ...     ...  \n",
      "3418.0             50       0       0       2       0  \n",
      "3421.0              0      12       0       0       0  \n",
      "3422.0              0       0      10       0       0  \n",
      "3425.0              2       0       0      30       0  \n",
      "3430.0              0       0       0       0       3  \n",
      "\n",
      "[272 rows x 272 columns]\n"
     ]
    }
   ],
   "source": [
    "od_matrix = pd.crosstab(df_bike_active['start_station'], df_bike_active['end_station'])\n",
    "\n",
    "print(od_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624ca16",
   "metadata": {},
   "source": [
    "Last major component I need before building my model is a distance dataframe, that can calculate\n",
    "the distance between stations. I do this by first making a new dataframe with the lat/lon coords for\n",
    "each station ID, and then calculating the Euclidean distances by convering the lat/long coords\n",
    "to radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique stations DataFrame created from start stations only:\n",
      "             latitude  longitude\n",
      "station_id                      \n",
      "3160.0      39.956619 -75.198624\n",
      "3006.0      39.952202  -75.20311\n",
      "3010.0      39.947109 -75.166183\n",
      "3026.0       39.94138 -75.145638\n",
      "3037.0      39.954239 -75.161377\n"
     ]
    }
   ],
   "source": [
    "df_stations = df_bike_active[['start_station', 'start_lat', 'start_lon']].rename(\n",
    "    columns={'start_station': 'station_id', 'start_lat': 'latitude', 'start_lon': 'longitude'}\n",
    ")\n",
    "df_stations = df_stations.drop_duplicates(subset='station_id')\n",
    "df_stations = df_stations.set_index('station_id')\n",
    "\n",
    "print(\"Unique stations DataFrame created from start stations only:\")\n",
    "print(df_stations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b3a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances DataFrame (in km) created successfully:\n",
      "   origin_id  destination_id  distance_km\n",
      "0     3160.0          3160.0     0.000000\n",
      "1     3160.0          3006.0     0.622444\n",
      "2     3160.0          3010.0     2.960575\n",
      "3     3160.0          3026.0     4.824125\n",
      "4     3160.0          3037.0     3.185790\n"
     ]
    }
   ],
   "source": [
    "# Filter out stations with missing lat/long, like Station ID 3000\n",
    "df_stations.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "# Prepare Coordinates in radians\n",
    "station_coords_radians = np.radians(df_stations[['latitude', 'longitude']].values.astype(float))\n",
    "\n",
    "# Calculate Haversine Distance Matrix\n",
    "dist_matrix_radians = haversine_distances(station_coords_radians)\n",
    "\n",
    "# Convert to Kilometers\n",
    "earth_radius_km = 6371\n",
    "dist_matrix_km = dist_matrix_radians * earth_radius_km\n",
    "\n",
    "# Convert to a Long-Format DataFrame\n",
    "df_distances = pd.DataFrame(dist_matrix_km, index=df_stations.index, columns=df_stations.index)\n",
    "df_distances = df_distances.unstack().reset_index(name='distance_km')\n",
    "df_distances.columns = ['origin_id', 'destination_id', 'distance_km']\n",
    "\n",
    "print(\"Distances DataFrame (in km) created successfully:\")\n",
    "print(df_distances.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
